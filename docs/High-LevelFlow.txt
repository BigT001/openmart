# ğŸ§  OpenMart: End-to-End System Workflow Documentation

## ğŸ”§ Project Overview

**OpenMart** is a smart, AI-powered social commerce platform that lets users search for products posted by vendors on social media platforms. Users can enter natural language prompts (e.g., "Red bag under 20k"), and the system will fetch, filter, and display matching items posted on Instagram, TikTok, etc., allowing users to shop directly through OpenMart.

---

## ğŸ§± Tech Stack Summary

### âš™ï¸ Frontend

* **Next.js + TailwindCSS + TypeScript**
* State/Data Layer: React Query (TanStack)
* UI Library: ShadCN

### âš™ï¸ Backend

* **FastAPI (Main) / Django (Optional for admin CMS)**

### ğŸ“¦ Database

* **PostgreSQL** (Structured Data)
* **ChromaDB** (Vector DB for semantic search and memory)

### ğŸ§  AI/LLM Layer

* **DeepSeek API** â€“ For interpreting user prompts
* **LangChain** â€“ Orchestration layer for tools, prompt routing, and memory

### ğŸ“„ Scraping Layer

* **Instaloader + Selenium + Requests + BeautifulSoup** â€“ For scraping product data from vendors' social media accounts

---

## ğŸ§­ Prompt-to-Feedback Flow (End-to-End)

### ğŸ”¹ Step 1: User Enters Prompt

User types a prompt:

> "I need an iPhone 13 under 500k"

### ğŸ”¹ Step 2: Request Sent to FastAPI Backend

The frontend sends this request to the FastAPI backend:

```ts
POST /api/search
{
  "prompt": "iPhone 13 under 500k"
}
```

### ğŸ”¹ Step 3: FastAPI Routes Request to LangChain

* LangChain handles prompt interpretation via DeepSeek or Gemini.
* The prompt is transformed into structured parameters:

```json
{
  "product": "iPhone 13",
  "max_price": 500000,
  "tags": ["iPhone", "Apple"]
}
```

### ğŸ”¹ Step 4: Product Discovery Pipeline Begins

LangChain triggers scraping/searching tools:

* ğŸ•µï¸â€â™€ï¸ Uses **ChromaDB** to look for semantically matched past product posts.
* ğŸ” Triggers **scrapers** (Instaloader, Selenium, etc.) to fetch fresh Instagram/TikTok posts tagged with iPhones.

### ğŸ”¹ Step 5: Extracted Data Is Cleaned & Enriched

* Caption, price, image, link, and seller info are extracted.
* AI auto-tags and auto-categorizes the data.
* The product listing is stored in **PostgreSQL** for structure and in **ChromaDB** for semantic recall.

### ğŸ”¹ Step 6: Products Are Filtered & Ranked

* Filtered by budget, keywords, category, recency.
* Sorted by AI relevance or trending products.

### ğŸ”¹ Step 7: Results Sent Back to Frontend

FastAPI sends a structured response back to the frontend:

```json
[
  {
    "title": "iPhone 13 - â‚¦485,000",
    "image": "https://...",
    "seller": "@techsource",
    "source": "Instagram",
    "post_url": "https://instagram.com/...",
    "add_to_cart": true
  },
  ...
]
```

### ğŸ”¹ Step 8: User Views, Adds to Cart, and Orders

* Products are displayed using **React Query** + **ShadCN** components.
* User adds to cart and proceeds to order.
* Order details are saved in **PostgreSQL**.
* Vendor is notified (via DM or webhook depending on future automation).

---

## ğŸ”„ Feedback Loop and Memory

* All prompts are logged.
* Frequently asked prompts are stored.
* ChromaDB helps the AI remember user patterns/preferences.

---

## ğŸ› ï¸ Admin / Vendor Dashboard (Optional Phase)

* View orders by vendor
* Review scraped posts
* Manage flagged listings

Built optionally using Django or a custom FastAPI dashboard.

---

## ğŸ” Authentication & Onboarding

* Users and vendors sign in via **social login** (e.g., Instagram, TikTok).
* OAuth tokens are used to fetch public posts for scraping.

---

## ğŸŒ External APIs Used

* **DeepSeek** â€“ Prompt interpretation (LLM)
* **LangChain** â€“ Agent orchestration
* **Gemini** (optional) â€“ Alternate LLM for fallback or co-processing
* **Social Media APIs** (optional) â€“ For structured vendor post access in future

---

## ğŸ”š Summary

This architecture creates a seamless AI-powered social commerce engine:

* **Prompt in â†’ Products out**
* No product listing needed by vendors
* AI + scraping powers discovery
* PostgreSQL + ChromaDB manage structured and semantic data

Would you like this exported as a PDF or Notion page?
